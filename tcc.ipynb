{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treinamento: 4569\n",
      "Número de imagens de validação: 1143\n",
      "Número de imagens de teste: 1311\n"
     ]
    }
   ],
   "source": [
    "# Diretório que contém as pastas Training e Testing\n",
    "data_dir = r'C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)'\n",
    "\n",
    "# Listando os diretórios de treinamento e teste\n",
    "train_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Testing')\n",
    "\n",
    "# Carregando as imagens e retornando os caminhos dos arquivos e rótulos\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "            images.append(img_path)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Carregando imagens e rótulos de treinamento\n",
    "train_images, train_labels = load_images_from_directory(train_dir)\n",
    "\n",
    "# Carregando imagens e rótulos de teste\n",
    "test_images, test_labels = load_images_from_directory(test_dir)\n",
    "\n",
    "# Dividindo os dados de treinamento em treinamento e validação\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Codificando os rótulos com LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# Convertendo rótulos para tipo inteiro\n",
    "train_labels = train_labels_encoded.astype(int)\n",
    "val_labels = val_labels_encoded.astype(int)\n",
    "\n",
    "# Exibindo as informações dos dados\n",
    "print(\"Número de imagens de treinamento:\", len(train_images))\n",
    "print(\"Número de imagens de validação:\", len(val_images))\n",
    "print(\"Número de imagens de teste:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato das imagens de validação: (1143, 32, 32, 3)\n",
      "Tipo das imagens de validação: float32\n"
     ]
    }
   ],
   "source": [
    "# Carregar e pré-processar imagens de validação\n",
    "def load_images_from_paths(image_paths):\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(32, 32))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        images.append(img_array)\n",
    "    return np.array(images)\n",
    "\n",
    "val_images_processed = load_images_from_paths(val_images)\n",
    "\n",
    "# Verificar o formato das imagens de validação processadas\n",
    "print(\"Formato das imagens de validação:\", val_images_processed.shape)\n",
    "print(\"Tipo das imagens de validação:\", val_images_processed.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4445 - loss: 1.1550 - val_accuracy: 0.7210 - val_loss: 0.7087\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7421 - loss: 0.6653 - val_accuracy: 0.7877 - val_loss: 0.5695\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7915 - loss: 0.5268 - val_accuracy: 0.8042 - val_loss: 0.5230\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8130 - loss: 0.4766 - val_accuracy: 0.7823 - val_loss: 0.5383\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8470 - loss: 0.4054 - val_accuracy: 0.8414 - val_loss: 0.4317\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8587 - loss: 0.3624 - val_accuracy: 0.8381 - val_loss: 0.4325\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8827 - loss: 0.3159 - val_accuracy: 0.8468 - val_loss: 0.4150\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8820 - loss: 0.3076 - val_accuracy: 0.8545 - val_loss: 0.3794\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9018 - loss: 0.2713 - val_accuracy: 0.8337 - val_loss: 0.4499\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2353 - val_accuracy: 0.8589 - val_loss: 0.3908\n",
      "Fold 2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4143 - loss: 1.1771 - val_accuracy: 0.7352 - val_loss: 0.7043\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7324 - loss: 0.6897 - val_accuracy: 0.7998 - val_loss: 0.5447\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7665 - loss: 0.5757 - val_accuracy: 0.8282 - val_loss: 0.4628\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8223 - loss: 0.4799 - val_accuracy: 0.8107 - val_loss: 0.4985\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8337 - loss: 0.4370 - val_accuracy: 0.8534 - val_loss: 0.4006\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8539 - loss: 0.3854 - val_accuracy: 0.8556 - val_loss: 0.3819\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8742 - loss: 0.3341 - val_accuracy: 0.8600 - val_loss: 0.3714\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.3360 - val_accuracy: 0.8151 - val_loss: 0.4888\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8986 - loss: 0.2769 - val_accuracy: 0.8676 - val_loss: 0.3390\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9136 - loss: 0.2326 - val_accuracy: 0.8687 - val_loss: 0.3407\n",
      "Fold 3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4271 - loss: 1.2004 - val_accuracy: 0.7396 - val_loss: 0.7203\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7518 - loss: 0.6552 - val_accuracy: 0.7910 - val_loss: 0.5931\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8089 - loss: 0.5059 - val_accuracy: 0.8031 - val_loss: 0.5067\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8294 - loss: 0.4418 - val_accuracy: 0.8249 - val_loss: 0.4548\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8596 - loss: 0.3828 - val_accuracy: 0.8326 - val_loss: 0.4338\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8773 - loss: 0.3302 - val_accuracy: 0.8534 - val_loss: 0.4088\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8757 - loss: 0.3297 - val_accuracy: 0.8468 - val_loss: 0.3912\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8979 - loss: 0.2666 - val_accuracy: 0.8807 - val_loss: 0.3324\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.2386 - val_accuracy: 0.8818 - val_loss: 0.3214\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9313 - loss: 0.1930 - val_accuracy: 0.8720 - val_loss: 0.3672\n",
      "Fold 4\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.4154 - loss: 1.2100 - val_accuracy: 0.6991 - val_loss: 0.8172\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7604 - loss: 0.6519 - val_accuracy: 0.7702 - val_loss: 0.5717\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8053 - loss: 0.5232 - val_accuracy: 0.8020 - val_loss: 0.5526\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8443 - loss: 0.4089 - val_accuracy: 0.8118 - val_loss: 0.5070\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8529 - loss: 0.3879 - val_accuracy: 0.8337 - val_loss: 0.4761\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8808 - loss: 0.3175 - val_accuracy: 0.8217 - val_loss: 0.4688\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8989 - loss: 0.2693 - val_accuracy: 0.8392 - val_loss: 0.4206\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8837 - loss: 0.2959 - val_accuracy: 0.8545 - val_loss: 0.4153\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9108 - loss: 0.2342 - val_accuracy: 0.8687 - val_loss: 0.3727\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9385 - loss: 0.1842 - val_accuracy: 0.8589 - val_loss: 0.4362\n",
      "Fold 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.4620 - loss: 1.1504 - val_accuracy: 0.6911 - val_loss: 0.7987\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7406 - loss: 0.6921 - val_accuracy: 0.7809 - val_loss: 0.5396\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7976 - loss: 0.5258 - val_accuracy: 0.8094 - val_loss: 0.4745\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8304 - loss: 0.4353 - val_accuracy: 0.8324 - val_loss: 0.4313\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8586 - loss: 0.3846 - val_accuracy: 0.8423 - val_loss: 0.3872\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8417 - loss: 0.3901 - val_accuracy: 0.8105 - val_loss: 0.4563\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8708 - loss: 0.3133 - val_accuracy: 0.8587 - val_loss: 0.3700\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9013 - loss: 0.2752 - val_accuracy: 0.8412 - val_loss: 0.3853\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8986 - loss: 0.2602 - val_accuracy: 0.8708 - val_loss: 0.3200\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9193 - loss: 0.2168 - val_accuracy: 0.8762 - val_loss: 0.3200\n"
     ]
    }
   ],
   "source": [
    "# Função para definir a arquitetura da LeNet-5\n",
    "def LeNet5(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Definindo as variáveis input_shape e num_classes\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 4\n",
    "\n",
    "# Aplicando a validação cruzada K-Fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    fold_train_images = [train_images[i] for i in train_indices]\n",
    "    fold_train_labels = [train_labels[i] for i in train_indices]\n",
    "    fold_val_images = [train_images[i] for i in val_indices]\n",
    "    fold_val_labels = [train_labels[i] for i in val_indices]\n",
    "    \n",
    "    # Carregar e pré-processar imagens de treinamento e validação\n",
    "    fold_train_images_processed = []\n",
    "    fold_val_images_processed = []\n",
    "    for img_path in fold_train_images:\n",
    "        img = load_img(img_path, target_size=(32, 32))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        fold_train_images_processed.append(img_array)\n",
    "    for img_path in fold_val_images:\n",
    "        img = load_img(img_path, target_size=(32, 32))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0\n",
    "        fold_val_images_processed.append(img_array)\n",
    "    \n",
    "    fold_train_images_processed = np.array(fold_train_images_processed)\n",
    "    fold_val_images_processed = np.array(fold_val_images_processed)\n",
    "    \n",
    "    # Codificar rótulos\n",
    "    label_encoder = LabelEncoder()\n",
    "    fold_train_labels_encoded = label_encoder.fit_transform(fold_train_labels)\n",
    "    fold_val_labels_encoded = label_encoder.transform(fold_val_labels)\n",
    "    \n",
    "    # Converter rótulos para tipo inteiro\n",
    "    fold_train_labels = fold_train_labels_encoded.astype(int)\n",
    "    fold_val_labels = fold_val_labels_encoded.astype(int)\n",
    "    \n",
    "    # Definindo a arquitetura da LeNet-5 para cada fold\n",
    "    model = LeNet5(input_shape, num_classes)\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Treinamento do modelo para cada fold\n",
    "    model.fit(x=fold_train_images_processed, y=fold_train_labels,\n",
    "              validation_data=(fold_val_images_processed, fold_val_labels),\n",
    "              epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4109 - loss: 1.1940 - val_accuracy: 0.7046 - val_loss: 0.6956\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7641 - loss: 0.6375 - val_accuracy: 0.7713 - val_loss: 0.5822\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8109 - loss: 0.5045 - val_accuracy: 0.8096 - val_loss: 0.5051\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8388 - loss: 0.4284 - val_accuracy: 0.7987 - val_loss: 0.4915\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8541 - loss: 0.3875 - val_accuracy: 0.8260 - val_loss: 0.4297\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8664 - loss: 0.3575 - val_accuracy: 0.8217 - val_loss: 0.4384\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.3047 - val_accuracy: 0.8184 - val_loss: 0.4539\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2624 - val_accuracy: 0.8687 - val_loss: 0.3602\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9289 - loss: 0.2085 - val_accuracy: 0.8239 - val_loss: 0.4385\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9179 - loss: 0.2303 - val_accuracy: 0.8611 - val_loss: 0.4038\n"
     ]
    }
   ],
   "source": [
    "def LeNet5(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Definindo as variáveis input_shape e num_classes\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 4\n",
    "\n",
    "# Aplicando a validação cruzada K-Fold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Escolhendo o fold desejado\n",
    "chosen_fold = 3\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images)):\n",
    "    if fold == chosen_fold:\n",
    "        print(f\"Fold {fold}\")\n",
    "        fold_train_images = [train_images[i] for i in train_indices]\n",
    "        fold_train_labels = [train_labels[i] for i in train_indices]\n",
    "        fold_val_images = [train_images[i] for i in val_indices]\n",
    "        fold_val_labels = [train_labels[i] for i in val_indices]\n",
    "\n",
    "        # Carregar e pré-processar imagens de treinamento e validação\n",
    "        fold_train_images_processed = []\n",
    "        fold_val_images_processed = []\n",
    "        for img_path in fold_train_images:\n",
    "            img = load_img(img_path, target_size=(32, 32))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0\n",
    "            fold_train_images_processed.append(img_array)\n",
    "        for img_path in fold_val_images:\n",
    "            img = load_img(img_path, target_size=(32, 32))\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array / 255.0\n",
    "            fold_val_images_processed.append(img_array)\n",
    "\n",
    "        fold_train_images_processed = np.array(fold_train_images_processed)\n",
    "        fold_val_images_processed = np.array(fold_val_images_processed)\n",
    "\n",
    "        # Codificar rótulos\n",
    "        label_encoder = LabelEncoder()\n",
    "        fold_train_labels_encoded = label_encoder.fit_transform(fold_train_labels)\n",
    "        fold_val_labels_encoded = label_encoder.transform(fold_val_labels)\n",
    "\n",
    "        # Converter rótulos para tipo inteiro\n",
    "        fold_train_labels = fold_train_labels_encoded.astype(int)\n",
    "        fold_val_labels = fold_val_labels_encoded.astype(int)\n",
    "\n",
    "        # Definindo a arquitetura da LeNet-5 para cada fold\n",
    "        model = LeNet5(input_shape, num_classes)\n",
    "\n",
    "        # Compilando o modelo\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        # Treinamento do modelo para cada fold\n",
    "        model.fit(x=fold_train_images_processed, y=fold_train_labels,\n",
    "                  validation_data=(fold_val_images_processed, fold_val_labels),\n",
    "                  epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo treinado\n",
    "model.save('LeNet5Kfold_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "LeNet5ModelKfold = load_model('LeNet5Kfold_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "Classe Pituary: 3\n"
     ]
    }
   ],
   "source": [
    "# Carregando a imagem que para classificar\n",
    "img_path = r\"C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)\\Testing\\pituitary\\Te-pi_0054.jpg\"\n",
    "img = image.load_img(img_path, target_size=(32, 32))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Adicionando uma dimensão extra para se adequar ao formato esperado pelo modelo\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Fazendo a previsão usando o modelo\n",
    "predictions = LeNet5ModelKfold.predict(img_array)\n",
    "\n",
    "# Índice com maior probabilidade\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Classe prevista\n",
    "if predicted_class == 0:\n",
    "    print(\"Classe Glioma:\", predicted_class)\n",
    "elif predicted_class == 1:\n",
    "    print(\"Classe Meningioma:\", predicted_class)\n",
    "elif predicted_class == 2:\n",
    "    print(\"Classe Notumor:\", predicted_class)\n",
    "elif predicted_class == 3:\n",
    "    print(\"Classe Pituary:\", predicted_class)\n",
    "else:\n",
    "    print('Classe não encontrada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Acurácia: 0.9268986649157365\n"
     ]
    }
   ],
   "source": [
    "# Carregar e pré-processar imagens de treinamento\n",
    "train_images_processed = load_images_from_paths(train_images)\n",
    "\n",
    "# Fazer a previsão do conjunto de validação\n",
    "train_predictions = LeNet5ModelKfold.predict(train_images_processed)\n",
    "train_predictions_classes = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(train_labels, train_predictions_classes)\n",
    "print(\"Acurácia:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(train_labels, train_predictions_classes)\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix (Training)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.85      0.96      0.91      1033\n",
      "  meningioma       0.94      0.78      0.85      1074\n",
      "     notumor       0.98      0.97      0.97      1304\n",
      "   pituitary       0.94      0.99      0.96      1158\n",
      "\n",
      "    accuracy                           0.93      4569\n",
      "   macro avg       0.93      0.92      0.92      4569\n",
      "weighted avg       0.93      0.93      0.93      4569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precisão, recall e F1-score\n",
    "report = classification_report(train_labels, train_predictions_classes, target_names=label_encoder.classes_)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treinamento: 4569\n",
      "Número de imagens de validação: 1143\n",
      "Número de imagens de teste: 1311\n"
     ]
    }
   ],
   "source": [
    "# Diretório que contém as pastas Training e Testing\n",
    "data_dir = r'C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)'\n",
    "\n",
    "# Listando os diretórios de treinamento e teste\n",
    "train_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Testing')\n",
    "\n",
    "# Carregando as imagens e retornando os caminhos dos arquivos e rótulos\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "            images.append(img_path)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Carregando imagens e rótulos de treinamento\n",
    "train_images, train_labels = load_images_from_directory(train_dir)\n",
    "\n",
    "# Carregando imagens e rótulos de teste\n",
    "test_images, test_labels = load_images_from_directory(test_dir)\n",
    "\n",
    "# Dividindo os dados de treinamento em treinamento e validação\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Codificando os rótulos com LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# Convertendo rótulos para tipo inteiro\n",
    "train_labels = train_labels_encoded.astype(int)\n",
    "val_labels = val_labels_encoded.astype(int)\n",
    "\n",
    "# Exibindo as informações dos dados\n",
    "print(\"Número de imagens de treinamento:\", len(train_images))\n",
    "print(\"Número de imagens de validação:\", len(val_images))\n",
    "print(\"Número de imagens de teste:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para pré-processar imagens\n",
    "def preprocess_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(227, 227))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Função para pré-processar um lote de imagens\n",
    "def preprocess_images_in_batches(image_paths, batch_size=32):\n",
    "    images_processed = []\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_images = [preprocess_image(image_path) for image_path in batch_paths]\n",
    "        images_processed.extend(batch_images)\n",
    "    return np.array(images_processed)\n",
    "\n",
    "# Exibindo as informações dos dados\n",
    "batch_size = 32\n",
    "train_images_processed = preprocess_images_in_batches(train_images, batch_size=batch_size)\n",
    "val_images_processed = preprocess_images_in_batches(val_images, batch_size=batch_size)\n",
    "test_images_processed = preprocess_images_in_batches(test_images, batch_size=batch_size)\n",
    "train_images_processed = preprocess_images_in_batches(train_images, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.5352 - loss: 5.0689 - val_accuracy: 0.2429 - val_loss: 3.3616\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.7653 - loss: 0.6396 - val_accuracy: 0.4978 - val_loss: 1.8671\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.7631 - loss: 0.6496 - val_accuracy: 0.6324 - val_loss: 1.3004\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.7618 - loss: 0.6778 - val_accuracy: 0.8195 - val_loss: 0.5112\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8398 - loss: 0.4466 - val_accuracy: 0.6849 - val_loss: 0.7787\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8392 - loss: 0.4378 - val_accuracy: 0.7560 - val_loss: 0.6462\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8576 - loss: 0.4035 - val_accuracy: 0.6368 - val_loss: 0.9498\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8475 - loss: 0.4357 - val_accuracy: 0.6740 - val_loss: 1.2362\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.8432 - loss: 0.4918 - val_accuracy: 0.8282 - val_loss: 0.6162\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8641 - loss: 0.4004 - val_accuracy: 0.8435 - val_loss: 0.4430\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 1s/step - accuracy: 0.5196 - loss: 5.1500 - val_accuracy: 0.3468 - val_loss: 3.9293\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.6915 - loss: 0.9284 - val_accuracy: 0.5350 - val_loss: 1.3271\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.7474 - loss: 0.6920 - val_accuracy: 0.6674 - val_loss: 0.8553\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.7965 - loss: 0.6064 - val_accuracy: 0.7177 - val_loss: 0.7822\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7976 - loss: 0.5632 - val_accuracy: 0.4814 - val_loss: 3.2644\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8088 - loss: 0.5275 - val_accuracy: 0.7615 - val_loss: 0.6721\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8533 - loss: 0.4392 - val_accuracy: 0.6225 - val_loss: 1.6959\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.8583 - loss: 0.4086 - val_accuracy: 0.7309 - val_loss: 0.9113\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.8568 - loss: 0.4266 - val_accuracy: 0.8425 - val_loss: 0.5007\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.8613 - loss: 0.3908 - val_accuracy: 0.7123 - val_loss: 0.7673\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 1s/step - accuracy: 0.5259 - loss: 7.1125 - val_accuracy: 0.3643 - val_loss: 2.3606\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.6727 - loss: 0.8220 - val_accuracy: 0.4661 - val_loss: 1.2217\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.7115 - loss: 0.7270 - val_accuracy: 0.6291 - val_loss: 0.8226\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7492 - loss: 0.6515 - val_accuracy: 0.6357 - val_loss: 0.8738\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.7985 - loss: 0.5669 - val_accuracy: 0.7593 - val_loss: 0.6411\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8081 - loss: 0.5089 - val_accuracy: 0.8392 - val_loss: 0.4367\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8129 - loss: 0.4944 - val_accuracy: 0.8009 - val_loss: 0.5076\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8332 - loss: 0.4708 - val_accuracy: 0.4683 - val_loss: 2.6925\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8524 - loss: 0.4138 - val_accuracy: 0.7024 - val_loss: 0.8940\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8388 - loss: 0.4284 - val_accuracy: 0.8632 - val_loss: 0.3710\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 1s/step - accuracy: 0.5286 - loss: 6.5639 - val_accuracy: 0.4114 - val_loss: 2.7590\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.6833 - loss: 0.9991 - val_accuracy: 0.4836 - val_loss: 1.3253\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.7567 - loss: 0.6826 - val_accuracy: 0.7341 - val_loss: 0.6746\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.7821 - loss: 0.6218 - val_accuracy: 0.6958 - val_loss: 0.7338\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7966 - loss: 0.5518 - val_accuracy: 0.7232 - val_loss: 0.6649\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.8269 - loss: 0.5102 - val_accuracy: 0.5788 - val_loss: 1.1024\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.8211 - loss: 0.4907 - val_accuracy: 0.6335 - val_loss: 0.9592\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 1s/step - accuracy: 0.7728 - loss: 0.6582 - val_accuracy: 0.2921 - val_loss: 8.7893\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.8476 - loss: 0.4325 - val_accuracy: 0.5481 - val_loss: 1.6900\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8506 - loss: 0.4294 - val_accuracy: 0.8348 - val_loss: 0.4564\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 1s/step - accuracy: 0.5325 - loss: 4.7954 - val_accuracy: 0.4556 - val_loss: 5.0562\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7307 - loss: 0.8130 - val_accuracy: 0.6079 - val_loss: 0.8882\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.7754 - loss: 0.6335 - val_accuracy: 0.4907 - val_loss: 1.6634\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.7822 - loss: 0.5753 - val_accuracy: 0.6867 - val_loss: 0.8231\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.8327 - loss: 0.4746 - val_accuracy: 0.8499 - val_loss: 0.4988\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - accuracy: 0.8236 - loss: 0.4842 - val_accuracy: 0.7327 - val_loss: 0.6371\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8303 - loss: 0.4762 - val_accuracy: 0.5323 - val_loss: 1.2986\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.8495 - loss: 0.4407 - val_accuracy: 0.8740 - val_loss: 0.4753\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - accuracy: 0.8692 - loss: 0.3747 - val_accuracy: 0.6594 - val_loss: 0.8463\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8483 - loss: 0.3980 - val_accuracy: 0.8740 - val_loss: 0.4009\n"
     ]
    }
   ],
   "source": [
    "# Tamanho das imagens\n",
    "input_shape = (227, 227, 3)\n",
    "\n",
    "# Número de classes\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Função para pré-processar imagens\n",
    "def preprocess_image(image_path):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(227, 227))\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Função para pré-processar um lote de imagens\n",
    "def preprocess_images_in_batches(image_paths, batch_size=32):\n",
    "    images_processed = []\n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_images = [preprocess_image(image_path) for image_path in batch_paths]\n",
    "        images_processed.extend(batch_images)\n",
    "    return np.array(images_processed)\n",
    "\n",
    "# Exibindo as informações dos dados\n",
    "batch_size = 32\n",
    "train_images_processed = preprocess_images_in_batches(train_images, batch_size=batch_size)\n",
    "val_images_processed = preprocess_images_in_batches(val_images, batch_size=batch_size)\n",
    "test_images_processed = preprocess_images_in_batches(test_images, batch_size=batch_size)\n",
    "\n",
    "# Definindo o modelo AlexNet\n",
    "def AlexNet(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Aplicando o K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista para armazenar as métricas de cada fold\n",
    "accuracy_per_fold = []\n",
    "\n",
    "# Iterando sobre os folds\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images_processed)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Separando os dados de treinamento e validação para este fold\n",
    "    fold_train_images = train_images_processed[train_indices]\n",
    "    fold_train_labels = train_labels_encoded[train_indices]\n",
    "    fold_val_images = train_images_processed[val_indices]\n",
    "    fold_val_labels = train_labels_encoded[val_indices]\n",
    "    \n",
    "    # Criando uma nova instância do modelo para cada fold\n",
    "    model = AlexNet(input_shape, num_classes)\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Treinando o modelo para este fold\n",
    "    model.fit(x=fold_train_images, y=fold_train_labels, validation_data=(fold_val_images, fold_val_labels), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 1s/step - accuracy: 0.5384 - loss: 6.0490 - val_accuracy: 0.1958 - val_loss: 12.4537\n",
      "Epoch 2/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 1s/step - accuracy: 0.6121 - loss: 1.0913 - val_accuracy: 0.5733 - val_loss: 1.1762\n",
      "Epoch 3/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7183 - loss: 0.7936 - val_accuracy: 0.5766 - val_loss: 1.0180\n",
      "Epoch 4/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7332 - loss: 0.7488 - val_accuracy: 0.7757 - val_loss: 0.5717\n",
      "Epoch 5/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7701 - loss: 0.6583 - val_accuracy: 0.6937 - val_loss: 0.7486\n",
      "Epoch 6/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8070 - loss: 0.5717 - val_accuracy: 0.7462 - val_loss: 0.6232\n",
      "Epoch 7/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8174 - loss: 0.5414 - val_accuracy: 0.2757 - val_loss: 9.6652\n",
      "Epoch 8/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.7988 - loss: 0.5944 - val_accuracy: 0.7396 - val_loss: 0.6755\n",
      "Epoch 9/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - accuracy: 0.8303 - loss: 0.5203 - val_accuracy: 0.6007 - val_loss: 0.9948\n",
      "Epoch 10/10\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 1s/step - accuracy: 0.8625 - loss: 0.4093 - val_accuracy: 0.2757 - val_loss: 28.9323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23ee3bdaff0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo o modelo AlexNet\n",
    "def AlexNet(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(4096, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Divisão dos dados de acordo com o fold escolhido\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "chosen_fold = 1\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images_processed)):\n",
    "    if fold == chosen_fold:\n",
    "        fold_train_images = train_images_processed[train_indices]\n",
    "        fold_train_labels = train_labels_encoded[train_indices]\n",
    "        fold_val_images = train_images_processed[val_indices]\n",
    "        fold_val_labels = train_labels_encoded[val_indices]\n",
    "        break\n",
    "\n",
    "# Criando uma nova instância do modelo AlexNet\n",
    "model = AlexNet(input_shape=(227, 227, 3), num_classes=num_classes)\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo com os dados do fold escolhido\n",
    "model.fit(x=fold_train_images, y=fold_train_labels,\n",
    "          validation_data=(fold_val_images, fold_val_labels),\n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo treinado\n",
    "model.save('AlexNetKfold_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "AlexNetKfold = load_model(\"AlexNetKfold_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "Classe Notumor: 2\n"
     ]
    }
   ],
   "source": [
    "# Carregando a imagem que para classificar\n",
    "img_path = r\"C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)\\Testing\\glioma\\Te-gl_0019.jpg\"\n",
    "img = image.load_img(img_path, target_size=(227, 227))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Adicionando uma dimensão extra para se adequar ao formato esperado pelo modelo\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Fazendo a previsão usando o modelo\n",
    "predictions = AlexNetKfold.predict(img_array)\n",
    "\n",
    "# Índice com maior probabilidade\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Classe prevista\n",
    "if predicted_class == 0:\n",
    "    print(\"Classe Glioma:\", predicted_class)\n",
    "elif predicted_class == 1:\n",
    "    print(\"Classe Meningioma:\", predicted_class)\n",
    "elif predicted_class == 2:\n",
    "    print(\"Classe Notumor:\", predicted_class)\n",
    "elif predicted_class == 3:\n",
    "    print(\"Classe Pituary:\", predicted_class)\n",
    "else:\n",
    "    print('Classe não encontrada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 377ms/step\n",
      "Acurácia (Training): 0.2856204858831254\n"
     ]
    }
   ],
   "source": [
    "# Fazer previsões usando o modelo AlexNet nos dados de treinamento\n",
    "train_predictions = AlexNetKfold.predict(train_images_processed)\n",
    "train_predictions_classes = np.argmax(train_predictions, axis=1)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy_train = accuracy_score(train_labels, train_predictions_classes)\n",
    "print(\"Acurácia (Training):\", accuracy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(train_labels, train_predictions_classes)\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix (Training)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       1.00      0.00      0.00      1033\n",
      "  meningioma       0.00      0.00      0.00      1074\n",
      "     notumor       0.29      1.00      0.44      1304\n",
      "   pituitary       0.00      0.00      0.00      1158\n",
      "\n",
      "    accuracy                           0.29      4569\n",
      "   macro avg       0.32      0.25      0.11      4569\n",
      "weighted avg       0.31      0.29      0.13      4569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Willi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precisão, recall e F1-score\n",
    "report = classification_report(train_labels, train_predictions_classes, target_names=label_encoder.classes_)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treinamento: 4569\n",
      "Número de imagens de validação: 1143\n",
      "Número de imagens de teste: 1311\n"
     ]
    }
   ],
   "source": [
    "# Diretório que contém as pastas Training e Testing\n",
    "data_dir = r'C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)'\n",
    "\n",
    "# Listando os diretórios de treinamento e teste\n",
    "train_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Testing')\n",
    "\n",
    "# Carregando as imagens e retornando os caminhos dos arquivos e rótulos\n",
    "def load_images_from_directory(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(directory):\n",
    "        label_dir = os.path.join(directory, label)\n",
    "        for img_file in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_file)\n",
    "            images.append(img_path)\n",
    "            labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Carregando imagens e rótulos de treinamento\n",
    "train_images, train_labels = load_images_from_directory(train_dir)\n",
    "\n",
    "# Carregando imagens e rótulos de teste\n",
    "test_images, test_labels = load_images_from_directory(test_dir)\n",
    "\n",
    "# Dividindo os dados de treinamento em treinamento e validação\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Codificando os rótulos com LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "val_labels_encoded = label_encoder.transform(val_labels)\n",
    "\n",
    "# Convertendo rótulos para tipo inteiro\n",
    "train_labels = train_labels_encoded.astype(int)\n",
    "val_labels = val_labels_encoded.astype(int)\n",
    "\n",
    "# Exibindo as informações dos dados\n",
    "print(\"Número de imagens de treinamento:\", len(train_images))\n",
    "print(\"Número de imagens de validação:\", len(val_images))\n",
    "print(\"Número de imagens de teste:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato das imagens de validação: (1143, 224, 224, 3)\n",
      "Tipo das imagens de validação: float32\n"
     ]
    }
   ],
   "source": [
    "def load_and_preprocess_images_for_resnet(image_paths):\n",
    "    processed_images = []\n",
    "    for img_path in image_paths:\n",
    "        img = load_img(img_path, target_size=(224, 224))\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n",
    "        processed_images.append(img_array)\n",
    "    return np.array(processed_images)\n",
    "\n",
    "train_images_processed = load_and_preprocess_images_for_resnet(train_images)\n",
    "val_images_processed = load_and_preprocess_images_for_resnet(val_images)\n",
    "\n",
    "print(\"Formato das imagens de validação:\", val_images_processed.shape)\n",
    "print(\"Tipo das imagens de validação:\", val_images_processed.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m520s\u001b[0m 3s/step - accuracy: 0.6217 - loss: 1.2510 - val_accuracy: 0.2546 - val_loss: 2273.3464\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3s/step - accuracy: 0.7699 - loss: 0.6218 - val_accuracy: 0.4339 - val_loss: 3.8055\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.8328 - loss: 0.4478 - val_accuracy: 0.4322 - val_loss: 4.0828\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.8460 - loss: 0.4055 - val_accuracy: 0.3605 - val_loss: 4.8949\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3s/step - accuracy: 0.8226 - loss: 0.4562 - val_accuracy: 0.5538 - val_loss: 3.2118\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8861 - loss: 0.3194 - val_accuracy: 0.3701 - val_loss: 1.9925\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.8814 - loss: 0.3171 - val_accuracy: 0.4934 - val_loss: 1.5413\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.9031 - loss: 0.2526 - val_accuracy: 0.6308 - val_loss: 1.2466\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3s/step - accuracy: 0.9128 - loss: 0.2322 - val_accuracy: 0.8093 - val_loss: 0.4787\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 3s/step - accuracy: 0.9330 - loss: 0.1860 - val_accuracy: 0.7402 - val_loss: 0.8570\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m519s\u001b[0m 3s/step - accuracy: 0.6314 - loss: 1.2225 - val_accuracy: 0.2546 - val_loss: 3382.2273\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3s/step - accuracy: 0.7879 - loss: 0.5611 - val_accuracy: 0.2546 - val_loss: 57.4086\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3s/step - accuracy: 0.8103 - loss: 0.5526 - val_accuracy: 0.3500 - val_loss: 6.1959\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8405 - loss: 0.4288 - val_accuracy: 0.4182 - val_loss: 2.3564\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3s/step - accuracy: 0.8789 - loss: 0.3363 - val_accuracy: 0.6369 - val_loss: 1.2819\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.9127 - loss: 0.2459 - val_accuracy: 0.6667 - val_loss: 1.5238\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 4s/step - accuracy: 0.9319 - loss: 0.1850 - val_accuracy: 0.3806 - val_loss: 4.3986\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 4s/step - accuracy: 0.9287 - loss: 0.2040 - val_accuracy: 0.8443 - val_loss: 0.5032\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 4s/step - accuracy: 0.9432 - loss: 0.1629 - val_accuracy: 0.2555 - val_loss: 21.8946\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 4s/step - accuracy: 0.9345 - loss: 0.1725 - val_accuracy: 0.7454 - val_loss: 0.9041\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 4s/step - accuracy: 0.6217 - loss: 1.3035 - val_accuracy: 0.2546 - val_loss: 16783.2188\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 4s/step - accuracy: 0.7328 - loss: 0.7037 - val_accuracy: 0.5171 - val_loss: 1.5134\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 4s/step - accuracy: 0.8043 - loss: 0.5185 - val_accuracy: 0.5766 - val_loss: 1.6491\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m501s\u001b[0m 4s/step - accuracy: 0.8321 - loss: 0.4485 - val_accuracy: 0.6894 - val_loss: 0.8129\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 3s/step - accuracy: 0.8433 - loss: 0.4358 - val_accuracy: 0.2546 - val_loss: 6.6826\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8841 - loss: 0.3273 - val_accuracy: 0.4208 - val_loss: 4.2160\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 3s/step - accuracy: 0.8965 - loss: 0.2884 - val_accuracy: 0.7043 - val_loss: 0.7134\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.9189 - loss: 0.2347 - val_accuracy: 0.4506 - val_loss: 4.9401\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.9080 - loss: 0.2547 - val_accuracy: 0.7393 - val_loss: 0.9528\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 3s/step - accuracy: 0.9349 - loss: 0.1882 - val_accuracy: 0.8863 - val_loss: 0.3064\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m515s\u001b[0m 3s/step - accuracy: 0.6170 - loss: 1.3872 - val_accuracy: 0.2546 - val_loss: 1264.2195\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.7570 - loss: 0.6339 - val_accuracy: 0.4094 - val_loss: 2.0979\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8186 - loss: 0.4699 - val_accuracy: 0.3920 - val_loss: 5.8841\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 3s/step - accuracy: 0.8289 - loss: 0.4592 - val_accuracy: 0.7655 - val_loss: 0.6528\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8765 - loss: 0.3527 - val_accuracy: 0.7410 - val_loss: 0.7446\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.8907 - loss: 0.3153 - val_accuracy: 0.8600 - val_loss: 0.5371\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.9021 - loss: 0.2634 - val_accuracy: 0.8618 - val_loss: 0.4285\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.9309 - loss: 0.1849 - val_accuracy: 0.5853 - val_loss: 2.2900\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.9273 - loss: 0.2024 - val_accuracy: 0.9090 - val_loss: 0.2759\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 3s/step - accuracy: 0.9524 - loss: 0.1437 - val_accuracy: 0.4707 - val_loss: 6.6691\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m535s\u001b[0m 3s/step - accuracy: 0.5829 - loss: 1.3656 - val_accuracy: 0.2546 - val_loss: 2069.0850\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 3s/step - accuracy: 0.7766 - loss: 0.5843 - val_accuracy: 0.5836 - val_loss: 1.0065\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 3s/step - accuracy: 0.8306 - loss: 0.4524 - val_accuracy: 0.8303 - val_loss: 0.4612\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 3s/step - accuracy: 0.8611 - loss: 0.3855 - val_accuracy: 0.7542 - val_loss: 0.6918\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 3s/step - accuracy: 0.8692 - loss: 0.3527 - val_accuracy: 0.5136 - val_loss: 1.6047\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 3s/step - accuracy: 0.8940 - loss: 0.3013 - val_accuracy: 0.8154 - val_loss: 0.5076\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 3s/step - accuracy: 0.8962 - loss: 0.2768 - val_accuracy: 0.6772 - val_loss: 1.0288\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.9118 - loss: 0.2573 - val_accuracy: 0.9090 - val_loss: 0.3215\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.9368 - loss: 0.1862 - val_accuracy: 0.8968 - val_loss: 0.3304\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 3s/step - accuracy: 0.9460 - loss: 0.1560 - val_accuracy: 0.7682 - val_loss: 0.7593\n"
     ]
    }
   ],
   "source": [
    "def ResidualBlock(x, filters, kernel_size=3, strides=1, activation='relu'):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(activation)(y)\n",
    "    \n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adiciona atalho à saída\n",
    "    y = layers.Add()([x, y])\n",
    "    y = layers.Activation(activation)(y)\n",
    "    return y\n",
    "\n",
    "def ResNet(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Cmada Convolucional Inicial\n",
    "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Pilha de blocos residuais\n",
    "    x = ResidualBlock(x, 64)\n",
    "    x = ResidualBlock(x, 64)\n",
    "    x = ResidualBlock(x, 64)\n",
    "    \n",
    "    x = ResidualBlock(x, 128, strides=2)\n",
    "    x = ResidualBlock(x, 128)\n",
    "    x = ResidualBlock(x, 128)\n",
    "    \n",
    "    x = ResidualBlock(x, 256, strides=2)\n",
    "    x = ResidualBlock(x, 256)\n",
    "    x = ResidualBlock(x, 256)\n",
    "    \n",
    "    x = ResidualBlock(x, 512, strides=2)\n",
    "    x = ResidualBlock(x, 512)\n",
    "    x = ResidualBlock(x, 512)\n",
    "    \n",
    "    # Pooling médio global\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Camada de saída\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # CCriação do modelo\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tamanho das imagens\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Número de classes\n",
    "num_classes = 4\n",
    "\n",
    "# Definindo o KFold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convertendo listas de caminhos de imagem e labels para numpy arrays\n",
    "train_images_np = np.array(train_images)\n",
    "train_labels_np = np.array(train_labels)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images_np)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Separando os dados de treinamento e validação para este fold\n",
    "    fold_train_images = train_images_processed[train_indices]\n",
    "    fold_train_labels = train_labels_encoded[train_indices]\n",
    "    fold_val_images = train_images_processed[val_indices]\n",
    "    fold_val_labels = train_labels_encoded[val_indices]\n",
    "    \n",
    "    # Criando uma nova instância do modelo para cada fold\n",
    "    model = ResNet(input_shape, num_classes)\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    model.fit(x=train_images_processed, y=train_labels, validation_data=(val_images_processed, val_labels), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m536s\u001b[0m 3s/step - accuracy: 0.6156 - loss: 1.3714 - val_accuracy: 0.2546 - val_loss: 803.6547\n",
      "Epoch 2/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m490s\u001b[0m 3s/step - accuracy: 0.7523 - loss: 0.6415 - val_accuracy: 0.2546 - val_loss: 10.6181\n",
      "Epoch 3/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 3s/step - accuracy: 0.8047 - loss: 0.5005 - val_accuracy: 0.4444 - val_loss: 2.2601\n",
      "Epoch 4/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m486s\u001b[0m 3s/step - accuracy: 0.8311 - loss: 0.4609 - val_accuracy: 0.4654 - val_loss: 1.2994\n",
      "Epoch 5/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3s/step - accuracy: 0.8616 - loss: 0.3920 - val_accuracy: 0.7393 - val_loss: 0.8343\n",
      "Epoch 6/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3s/step - accuracy: 0.8848 - loss: 0.3109 - val_accuracy: 0.4523 - val_loss: 3.8460\n",
      "Epoch 7/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 3s/step - accuracy: 0.9050 - loss: 0.2720 - val_accuracy: 0.6282 - val_loss: 1.3991\n",
      "Epoch 8/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 3s/step - accuracy: 0.9075 - loss: 0.2468 - val_accuracy: 0.8626 - val_loss: 0.3802\n",
      "Epoch 9/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 3s/step - accuracy: 0.9261 - loss: 0.2012 - val_accuracy: 0.4969 - val_loss: 2.7516\n",
      "Epoch 10/10\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 3s/step - accuracy: 0.9408 - loss: 0.1633 - val_accuracy: 0.8688 - val_loss: 0.3557\n"
     ]
    }
   ],
   "source": [
    "def ResidualBlock(x, filters, kernel_size=3, strides=1, activation='relu'):\n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Activation(activation)(y)\n",
    "    \n",
    "    y = layers.Conv2D(filters, kernel_size=kernel_size, strides=1, padding='same')(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    \n",
    "    if strides != 1 or x.shape[-1] != filters:\n",
    "        x = layers.Conv2D(filters, kernel_size=1, strides=strides, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Adiciona atalho à saída\n",
    "    y = layers.Add()([x, y])\n",
    "    y = layers.Activation(activation)(y)\n",
    "    return y\n",
    "\n",
    "def ResNet(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Camada convolucional inicial\n",
    "    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Pilha de blocos residuais\n",
    "    x = ResidualBlock(x, 64)\n",
    "    x = ResidualBlock(x, 64)\n",
    "    x = ResidualBlock(x, 64)\n",
    "    \n",
    "    x = ResidualBlock(x, 128, strides=2)\n",
    "    x = ResidualBlock(x, 128)\n",
    "    x = ResidualBlock(x, 128)\n",
    "    \n",
    "    x = ResidualBlock(x, 256, strides=2)\n",
    "    x = ResidualBlock(x, 256)\n",
    "    x = ResidualBlock(x, 256)\n",
    "    \n",
    "    x = ResidualBlock(x, 512, strides=2)\n",
    "    x = ResidualBlock(x, 512)\n",
    "    x = ResidualBlock(x, 512)\n",
    "    \n",
    "    # Pooling médio global\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # Camada de saída\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # Criação do modelo\n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Tamanho das imagens\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Número de classes\n",
    "num_classes = 4\n",
    "\n",
    "# Definindo o KFold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Convertendo listas de caminhos de imagem e labels para numpy arrays\n",
    "train_images_np = np.array(train_images)\n",
    "train_labels_np = np.array(train_labels)\n",
    "\n",
    "chosen_fold = 4\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_images_np)):\n",
    "    if fold == chosen_fold:\n",
    "        print(f\"Fold {fold}\")\n",
    "        \n",
    "        # Separando os dados de treinamento e validação para este fold\n",
    "        fold_train_images = train_images_processed[train_indices]\n",
    "        fold_train_labels = train_labels_encoded[train_indices]\n",
    "        fold_val_images = train_images_processed[val_indices]\n",
    "        fold_val_labels = train_labels_encoded[val_indices]\n",
    "        \n",
    "        # Criando uma nova instância do modelo para cada fold\n",
    "        model = ResNet(input_shape, num_classes)\n",
    "        \n",
    "        # Compilando o modelo\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "        \n",
    "        # Treinando o modelo\n",
    "        model.fit(x=train_images_processed, y=train_labels, validation_data=(val_images_processed, val_labels), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar o modelo treinado\n",
    "model.save('ResNetKfold_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o modelo treinado\n",
    "ResNetKfold_model = load_model(\"ResNetKfold_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Classe Pituary: 3\n"
     ]
    }
   ],
   "source": [
    "# Carregando a imagem que para classificar\n",
    "img_path = r\"C:\\Users\\Willi\\OneDrive\\Área de Trabalho\\tcc\\archive (2)\\Testing\\notumor\\Te-no_0013.jpg\"\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = img_array / 255.0\n",
    "\n",
    "# Adicionando uma dimensão extra para se adequar ao formato esperado pelo modelo\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Fazendo a previsão usando o modelo\n",
    "predictions = ResNetKfold_model.predict(img_array)\n",
    "\n",
    "# Índice com maior probabilidade\n",
    "predicted_class = np.argmax(predictions)\n",
    "\n",
    "# Classe prevista\n",
    "if predicted_class == 0:\n",
    "    print(\"Classe Glioma:\", predicted_class)\n",
    "elif predicted_class == 1:\n",
    "    print(\"Classe Meningioma:\", predicted_class)\n",
    "elif predicted_class == 2:\n",
    "    print(\"Classe Notumor:\", predicted_class)\n",
    "elif predicted_class == 3:\n",
    "    print(\"Classe Pituary:\", predicted_class)\n",
    "else:\n",
    "    print('Classe não encontrada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise da acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.9026045086452178\n",
      "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(train_labels, train_predictions_classes)\n",
    "print(\"Acurácia:\", accuracy)\n",
    "\n",
    "# Carregar e pré-processar imagens de treinamento\n",
    "train_images_processed = load_and_preprocess_images_for_resnet(train_images)\n",
    "\n",
    "# Fazer a previsão do conjunto de validação\n",
    "train_predictions = ResNetKfold_model.predict(train_images_processed)\n",
    "train_predictions_classes = np.argmax(train_predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "conf_matrix = confusion_matrix(train_labels, train_predictions_classes)\n",
    "\n",
    "# Exibir a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix (Training)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      glioma       0.80      0.94      0.87      1033\n",
      "  meningioma       0.88      0.76      0.82      1074\n",
      "     notumor       0.97      0.94      0.96      1304\n",
      "   pituitary       0.95      0.96      0.95      1158\n",
      "\n",
      "    accuracy                           0.90      4569\n",
      "   macro avg       0.90      0.90      0.90      4569\n",
      "weighted avg       0.91      0.90      0.90      4569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precisão, recall e F1-score\n",
    "report = classification_report(train_labels, train_predictions_classes, target_names=label_encoder.classes_)\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
